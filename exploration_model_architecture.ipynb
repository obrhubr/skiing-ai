{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 21:51:44.155887: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-01-26 21:51:44.155924: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_conv(hp):\n",
    "\tchannels = 6\n",
    "\tlength = 400\n",
    "\t\n",
    "\tinput_shape = (length, channels)\n",
    "\tnum_classes = 1\n",
    "\n",
    "\tinput_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "\tconv1 = keras.layers.Conv1D(filters=hp.Int(\"filters\", min_value=32, max_value=256, step=32), kernel_size=hp.Int(\"kernel_size\", min_value=2, max_value=12, step=2), padding=\"same\")(input_layer)\n",
    "\tconv1 = keras.layers.BatchNormalization()(conv1)\n",
    "\tconv1 = keras.layers.ReLu()(conv1)\n",
    "\n",
    "\tconv2 = keras.layers.Conv1D(filters=hp.Int(\"filters\", min_value=32, max_value=256, step=32), kernel_size=hp.Int(\"kernel_size\", min_value=2, max_value=12, step=2), padding=\"same\")(conv1)\n",
    "\tconv2 = keras.layers.BatchNormalization()(conv2)\n",
    "\tconv2 = keras.layers.ReLu()(conv2)\n",
    "\n",
    "\tconv3 = keras.layers.Conv1D(filters=hp.Int(\"filters\", min_value=32, max_value=256, step=32), kernel_size=hp.Int(\"kernel_size\", min_value=2, max_value=12, step=2), padding=\"same\")(conv2)\n",
    "\tconv3 = keras.layers.BatchNormalization()(conv3)\n",
    "\tconv3 = keras.layers.ReLu()(conv3)\n",
    "\n",
    "\tgap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "\toutput_layer = keras.layers.Dense(num_classes, activation=\"sigmoid\")(gap)\n",
    "\n",
    "\tmodel = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\tmodel.compile(\n",
    "\t\toptimizer=\"adam\",\n",
    "\t\tloss=\"binary_crossentropy\",\n",
    "\t\tmetrics=[\"accuracy\"],\n",
    "\t)\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset specific\n",
    "channels = 6\n",
    "data = 400\n",
    "\n",
    "print(\"Training on dataset with \", data, \"datapoints...\")\n",
    "(df, X_conv, y) = get_data_conv(\"train\", data, channels)\n",
    "(df, X_test_conv, y_test) = get_data_conv(\"test\", data, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train convolutional model\n",
    "import keras_tuner\n",
    "\n",
    "epochs = 60\n",
    "batch_size = 32\n",
    "\n",
    "print(\"Creating model...\")\n",
    "model = optimise_conv(keras_tuner.HyperParameters())\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=optimise_conv,\n",
    "    objective=\"val_accuracy\",\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"./models/optimise/tuner\",\n",
    "    project_name=\"skiingai\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Searcing for best configs model...\")\n",
    "tuner.search(X_conv, y, epochs=5, validation_data=(X_test_conv, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=1)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = best_model.evaluate(X_test_conv, y_test)\n",
    "print(\"Accuracy of model\", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"./models/optimised/best_tuned.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using best.keras convolutional model trained on 400 datapoints\n",
    "\n",
    "model = tf.keras.models.load_model('./models/optimise/best.keras')\n",
    "print(\"Evaluating model...\")\n",
    "result = model.evaluate(X_test_conv, y_test)\n",
    "print(\"Accuracy of model for \" + str(data) + \" datapoints: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train optimised model in full\n",
    "\n",
    "model = tf.keras.models.load_model('./models/optimise/best_tuned.keras')\n",
    "model.compile(\n",
    "\toptimizer=\"adam\",\n",
    "\tloss=\"binary_crossentropy\",\n",
    "\tmetrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/optimise/best_tuned_full.keras\",\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "model.fit(X_conv, y, \n",
    "\tbatch_size=32,\n",
    "\tepochs=60,\n",
    "\tcallbacks=[model_checkpoint_callback],\n",
    "\tvalidation_split=0.2,\n",
    "\tverbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./models/optimise/best_tuned.keras')\n",
    "model.compile(\n",
    "\toptimizer=\"adam\",\n",
    "\tloss=\"binary_crossentropy\",\n",
    "\tmetrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "result = model.evaluate(X_test_conv, y_test)\n",
    "print(\"Accuracy of model for \" + str(data) + \" datapoints: \", result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
